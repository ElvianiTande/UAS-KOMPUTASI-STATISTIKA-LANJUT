---
title: "UAS KOMPUTASI STATISTIKA LANJUT"
author: "ELVIANI TANDE"
date: "2022-12-20"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Text mining memiliki definisi menambang data yang berupa teks untuk mencari kata-kata yang mewakili isi dari dokumen sehingga dapat dilakukan analisa keterhubungan antar dokumen.

Wordcloud adalah metode untuk menampilkan data teks secara visual, sederhananya wordcloud adalah gambar yang menunjukkan daftar kata-kata yang digunakan dalam sebuah dokumen/website/situsweb, umumnya semakin banyak kata yang digunakan semakin besar ukuran kata tersebut dalam gambar.

Dataset yang saya gunakan yaitu dataset tentang ulasan aplikasi Spotify
Spotify adalah salah satu penyedia layanan streaming musik terbesar, dengan lebih dari 422 juta pengguna aktif bulanan, termasuk 182 juta pelanggan berbayar, per Maret 2022. Beberapa dari mereka tidak ragu untuk berbagi pengalaman mereka menggunakan aplikasi ini bersama dengan peringkat yang diberikan untuk menunjukkan seberapa puas mereka dengan Aplikasi
link dataset : https://www.kaggle.com/datasets/mfaaris/spotify-app-reviews-2022


```{r}
#Menginput library dan dataset
library(wordcloud)
library(tm)
library(textclean)
library(tidytext)
reviews <- read.csv("C:/Users/LENOVO/Pictures/reviews.csv")
head(reviews)
```

```{r}
#merubah file .csv tadi kedalam corpus
corpusdata <- Corpus(VectorSource(reviews$Review))
inspect(corpusdata[1:5])
```

CLEANING DATA
```{r}
#mengubah semua huruf kapital menjadi huruf kecil
data_casefolding <- tm_map(corpusdata,
                           content_transformer(tolower))
```

```{r}
#menghapus url pada dokumen
removeURL <- function(x)gsub("http[^[:space:]]*","",x)
dataURL <- tm_map(data_casefolding,
                  content_transformer(removeURL))
```

```{r}
#menghapus mention pada dokumen
remove.mention <- function(x) gsub("Q\\S+","",x)
data_mention <- tm_map(dataURL, remove.mention)
```

```{r}
#menghapus hashtag
remove.hashtag <- function(X) gsub ("#\\S+","", X)
data_hashtag <- tm_map(data_mention, remove.hashtag)
```

```{r}
#menghapus tanda baca
data_punctuation <- tm_map(data_hashtag, content_transformer(removePunctuation))
```

```{r}
#menghapus nomor
data_nonumber <- tm_map(data_punctuation,
                        content_transformer(removeNumbers))
```

```{r}
#stemmming atau menghapus imbuhan sehingga kata menjadi kata dasar
data_stemming <- tm_map(data_nonumber, stemDocument,
                        language = "english")
```

```{r}
#simpan stemming
databersih <- data.frame(text=unlist(sapply(data_stemming, "[")), stringsAsFactors = FALSE)

```
```{r}
#Menghapus Huruf yang Bukan Kata
databersih <- strip(databersih)
head(databersih)
```

```{r}
#Menghapus Kata yang tidak penting
databersih <-removeWords(databersih,c("a","i","at","my","is","it","of","so","to","be","or","in" ,"the","our","you","and","was","this","with","not","too","but","for","its","who","has","what","yet","your","out","else","more","own","are","abaut","just","because","all","etc","works","these","did","say","use","end","she","lot","can","not","for","saw","also","have","that","after","and","dont","than","cant",","))
head(databersih)

```

MEMBUAT WORDCLOUD

```{r}
#Mengubah Data Frame Menjadi Data Faktor
tdm <- TermDocumentMatrix(databersih)
m <- as.matrix(tdm)
v <- sort(rowSums(m),decreasing = TRUE)
```

```{r}
#Mengubah Data Faktor Menjadi Data Frame
d <- data.frame(word = names(v), freq = v)

wordcloud(d$word, d$freq,
          random.order = FALSE,
          max.words = 200,
          colors = brewer.pal(name = "Dark2",8 ))
```

Plot kata-kata yang paling sering muncul
```{r}
barplot(d[1:5,]$freq, las = 2, names.arg = d[1:5,]$word,
        col ="lightgreen", main ="Top 5 most frequent words",
        ylab = "Word frequencies")
```





